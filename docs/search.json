[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "I’m Kayleigh Tompkins - a researcher and former policy advisor (UK Government) focused on the intersection of international relations and institutional stability. I’m currently pursuing graduate studies in Public Policy at the University of Texas at Dallas (UTD)."
  },
  {
    "objectID": "index.html#research-interests",
    "href": "index.html#research-interests",
    "title": "Welcome!",
    "section": "Research Interests",
    "text": "Research Interests\nMy work focuses on why states leave international organizations and the challenges of maintaining international cooperation. I’m currently interested in:\n\nInternational Organizations\nDemocratic Backsliding\nPolitical Economy of Climate Change"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I began my academic journey in the UK with a Bachelor’s degree in History from the University of Oxford, St Anne’s College. Graduating just seven days after the UK’s vote to leave the EU in June 2016, I spent the next five years working for the UK government designing new policies which defined the UK’s approach to international trade disputes after Brexit.\nAfter a family relocation to the US in 2022, I helped lead UC Berkeley’s strategic engagement with its most important global and domestic partners. I re-embraced academia after moving to Dallas in 2024, beginning my graduate studies which are focused on the same question that inspired my career: why do states leave international organizations and how do those organizations respond to such exits?\n\nWhen not walking the halls of Green Hall, I enjoy hiking, running, team sports and hanging out with my husband and our two cats - Nellie and Norman who like to “help” with my research and coding."
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "Hello, Goodbye, Pay Later: Why States Withhold Funds from International Organizations. Working Paper\n\nAn extension of von Borzyskowski and Vabulas (2019), this paper examines the financial dimensions of state commitment and withdrawal from international organizations. \n\nSearching for Democracy: Citizen Perceptions of Democratic Backsliding with Samiul Haque.\n\nWe combine Google Trends data with the Democratic Erosion Events Database to identify if citizens can recognize and respond to incidences of democratic backsliding. It is scheduled to be presented at the Midwest Political Science Association (MPSA) in April 2026.\n\n\nSliding in the Polls: The Impact of Hurricane Helene on Voter Behavior in North Carolina with Mamie Cincotta.\n\nWe leverage landslide data and predicted hurricane path maps to investigate the impact of Hurricane Helene on voter turnout and behavior in the 2024 Presidential elections held in North Carolina. It is due to be presented at the Midwest Political Science Association (MPSA) in April 2026."
  },
  {
    "objectID": "research.html#current-projects",
    "href": "research.html#current-projects",
    "title": "Research",
    "section": "",
    "text": "Hello, Goodbye, Pay Later: Why States Withhold Funds from International Organizations. Working Paper\n\nAn extension of von Borzyskowski and Vabulas (2019), this paper examines the financial dimensions of state commitment and withdrawal from international organizations. \n\nSearching for Democracy: Citizen Perceptions of Democratic Backsliding with Samiul Haque.\n\nWe combine Google Trends data with the Democratic Erosion Events Database to identify if citizens can recognize and respond to incidences of democratic backsliding. It is scheduled to be presented at the Midwest Political Science Association (MPSA) in April 2026.\n\n\nSliding in the Polls: The Impact of Hurricane Helene on Voter Behavior in North Carolina with Mamie Cincotta.\n\nWe leverage landslide data and predicted hurricane path maps to investigate the impact of Hurricane Helene on voter turnout and behavior in the 2024 Presidential elections held in North Carolina. It is due to be presented at the Midwest Political Science Association (MPSA) in April 2026."
  },
  {
    "objectID": "research.html#academic-publications",
    "href": "research.html#academic-publications",
    "title": "Research",
    "section": "Academic Publications",
    "text": "Academic Publications\n\nPeinhardt, C. & Tompkins, K. (Under Review). Review of Exit from International Organizations, Costly Negotiation for Institutional Change. Perspectives on Politics."
  },
  {
    "objectID": "research.html#policy-reports",
    "href": "research.html#policy-reports",
    "title": "Research",
    "section": "Policy Reports",
    "text": "Policy Reports\n\nTompkins, K., Lentini, F., & Adam, E. (2025, August). The US-UK Economic Propsperity Deal: An Analysis from BritishAmerican Business. https://www.babinc.org/wp-content/uploads/The-US-UK-Economic-Prosperity-Deal-An-Analysis-from-BAB.pdf. BritishAmerican Business."
  },
  {
    "objectID": "Assignments.html",
    "href": "Assignments.html",
    "title": "Knowledge Mining",
    "section": "",
    "text": "In his provocative 2001 article “Statistical modeling: The two cultures”, Leo Breiman describes two opposing cultures in statistical sciences: one focused on using data to find causal parameters and identify causal relationships (“data modelling”) and the other which treats data mechanisms as a “black box” which forgoes causal understanding in favor of accurate predictions “algorithmic modeling” - now more commonly known as machine learning.\nBreiman critiques adherents of the data modeling approach for focusing too greatly on proving theorems that don’t capture real world intricacies, as well as the vulnerability of data modeling approachs to the strength of the assumptions made about their data (e.g. how it is distributed). He pointedly accuses his fellow statisticians of ignoring advances in algorithmic modeling which are able to solve complex challenges.\nDerided upon publication, Breiman radically challenged his peers to change the question that they explored, shifting from “why did this happen” to “what will happen next”. While this was a foundational critique of the field, his examples were mostly based on diagnosing and predicting medical illnesses, which do seem well suited to predictive approaches. However, while it is of course, useful, to predict who will get cancer, researchers could never conceive of abandoning research into what causes cancer.\nIn “To Explain or to Predict”, Galit Shmueli made several important contributions to this academic debate. Interestingly, she explains why a good explanatory model can be a bad predictor due overfitting the specific sample which increases variance when applied to new data - the Bias-Variance Trade-off. Predictive models, in contrast, prioritize minimizing a combination of bias and variance, and accept a little bias to reduce that variance, meaning that the addition of a “wrong” variable can make prediction more stable.\nShe outlines several useful uses of prediction to enhance explanatory work, including hypothesis generation, determining which way of measuring a concept is the most appropriate, improving explanations and theory comparison. She recommends using predictive models as a ceiling, first running the black box algorithm to see the maximum possible accuracy and then run the theory-based model. The gap (or lack of) between the two models generates important feedback as to whether the theory captures the phenomenon a researcher is trying to measure.\nTowards a third culture\nSince Breiman and Shmueli’s papers, a potential “third culture” has emerged which marries the strengths of each school of thought. This approach - Causal Machine Learning - uses predictive algorithms inside explanatory methods, combining the accuracy benefits of the algorithmic modeling culture to strengthen the scientific claims of the data modeling culture. For example, methods like Synthetic Control have a goal which is firmly rooted in explanatory, causal inference, but now employ predictive algorithms as the means to optimize the method - e.g. using Random Forests to perfectly weight the “control states” which serves as the counterfactual to the treated unit."
  },
  {
    "objectID": "index.html#professional-background",
    "href": "index.html#professional-background",
    "title": "Welcome!",
    "section": "Professional Background",
    "text": "Professional Background\nBefore returning to academia, I served as a Policy Advisor for the UK Government. This experience shapes my research, bridging the gap between theoretical political economy and practitioner insights.\nI recently served as a Policy Fellow with BritishAmerican Business where I analyzed transatlantic trade policy and published an analysis of the UK-US Economic Prosperity Deal."
  },
  {
    "objectID": "Assignments.html#assignment-1",
    "href": "Assignments.html#assignment-1",
    "title": "Knowledge Mining",
    "section": "",
    "text": "In his provocative 2001 article “Statistical modeling: The two cultures”, Leo Breiman describes two opposing cultures in statistical sciences: one focused on using data to find causal parameters and identify causal relationships (“data modelling”) and the other which treats data mechanisms as a “black box” which forgoes causal understanding in favor of accurate predictions “algorithmic modeling” - now more commonly known as machine learning.\nBreiman critiques adherents of the data modeling approach for focusing too greatly on proving theorems that don’t capture real world intricacies, as well as the vulnerability of data modeling approachs to the strength of the assumptions made about their data (e.g. how it is distributed). He pointedly accuses his fellow statisticians of ignoring advances in algorithmic modeling which are able to solve complex challenges.\nDerided upon publication, Breiman radically challenged his peers to change the question that they explored, shifting from “why did this happen” to “what will happen next”. While this was a foundational critique of the field, his examples were mostly based on diagnosing and predicting medical illnesses, which do seem well suited to predictive approaches. However, while it is of course, useful, to predict who will get cancer, researchers could never conceive of abandoning research into what causes cancer.\nIn “To Explain or to Predict”, Galit Shmueli made several important contributions to this academic debate. Interestingly, she explains why a good explanatory model can be a bad predictor due overfitting the specific sample which increases variance when applied to new data - the Bias-Variance Trade-off. Predictive models, in contrast, prioritize minimizing a combination of bias and variance, and accept a little bias to reduce that variance, meaning that the addition of a “wrong” variable can make prediction more stable.\nShe outlines several useful uses of prediction to enhance explanatory work, including hypothesis generation, determining which way of measuring a concept is the most appropriate, improving explanations and theory comparison. She recommends using predictive models as a ceiling, first running the black box algorithm to see the maximum possible accuracy and then run the theory-based model. The gap (or lack of) between the two models generates important feedback as to whether the theory captures the phenomenon a researcher is trying to measure.\nTowards a third culture\nSince Breiman and Shmueli’s papers, a potential “third culture” has emerged which marries the strengths of each school of thought. This approach - Causal Machine Learning - uses predictive algorithms inside explanatory methods, combining the accuracy benefits of the algorithmic modeling culture to strengthen the scientific claims of the data modeling culture. For example, methods like Synthetic Control have a goal which is firmly rooted in explanatory, causal inference, but now employ predictive algorithms as the means to optimize the method - e.g. using Random Forests to perfectly weight the “control states” which serves as the counterfactual to the treated unit."
  }
]