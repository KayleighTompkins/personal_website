---
title: "Knowledge Mining"
---

## Assignment 1:

In his provocative 2001 article "Statistical modeling: The two cultures", Leo Breiman describes two opposing cultures in statistical sciences: one focused on using data to find causal parameters and identify causal relationships ("data modelling") and the other which treats data mechanisms as a "black box" which forgoes causal understanding in favor of accurate predictions "algorithmic modeling" - now more commonly known as machine learning.

Breiman critiques adherents of the data modeling approach for focusing too greatly on proving theorems that don't capture real world intricacies, as well as the vulnerability of data modeling approachs to the strength of the assumptions made about their data (e.g. how it is distributed). He pointedly accuses his fellow statisticians of ignoring advances in algorithmic modeling which are able to solve complex challenges.

Derided upon publication, Breiman radically challenged his peers to change the question that they explored, shifting from "why did this happen" to "what will happen next". While this was a foundational critique of the field, his examples were mostly based on diagnosing and predicting medical illnesses, which do seem well suited to predictive approaches. However, while it is of course, useful, to predict who will get cancer, researchers could never conceive of abandoning research into what causes cancer.

In "To Explain or to Predict", Galit Shmueli made several important contributions to this academic debate. Interestingly, she explains why a good explanatory model can be a bad predictor due overfitting the specific sample which increases variance when applied to new data - the Bias-Variance Trade-off. Predictive models, in contrast, prioritize minimizing a combination of bias and variance, and accept a little bias to reduce that variance, meaning that the addition of a "wrong" variable can make prediction more stable.

She outlines several useful uses of prediction to enhance explanatory work, including hypothesis generation, determining which way of measuring a concept is the most appropriate, improving explanations and theory comparison. She recommends using predictive models as a ceiling, first running the black box algorithm to see the maximum possible accuracy and then run the theory-based model. The gap (or lack of) between the two models generates important feedback as to whether the theory captures the phenomenon a researcher is trying to measure.

Third culture:

Since Breiman and Shmueli's papers, a potential "third culture" has emerged which marries the strengths of each school of thought. This approach - Causal Machine Learning - uses predictive algorithms inside explanatory methods, combining the accuracy benefits of the algorithmic modeling culture to strengthen the scientific claims of the data modeling culture. For example, methods like Synthetic Control have a goal which is firmly rooted in explanatory, causal inference, but now employ predictive algorithms as the means to optimize the method - e.g. using Random Forests to perfectly weight the "control states" which serves as the counterfactual to the treated unit.
